--- 
 title: MKGFormer 
 date: 2024-07-05 14:53:42 
 updated: 2024-07-13
 mathjax: true
tags:
  - 持续学习
  - 论文阅读
---

## 综述
### Continual Learning Scenarios

#### Instance-Incremental Learning (IIL)
- **定义**: 所有训练样本属于相同任务，以批次到达。
- **训练**: {Dt,b, t}b∈Bt
- **测试**: {p(Xt)}t=j；不需要任务标识

#### Domain-Incremental Learning (DIL)
- **定义**: 任务具有相同的数据标签空间但不同的输入分布。任务标识不是必须的。
- **训练**: {Dt, t}t∈T；p(Xi) ̸= p(Xj) 且 Yi = Yj 对于 i ̸= j
- **测试**: {p(Xt)}t∈T；不需要任务标识

#### Task-Incremental Learning (TIL)
- **定义**: 任务具有不相交的数据标签空间。在训练和测试中提供任务标识。
- **训练**: {Dt, t}t∈T；p(Xi) ̸= p(Xj) 且 Yi ∩ Yj = ∅ 对于 i ̸= j
- **测试**: {p(Xt)}t∈T；提供任务标识

#### Class-Incremental Learning (CIL)
- **定义**: 任务具有不相交的数据标签空间。仅在训练中提供任务标识。
- **训练**: {Dt, t}t∈T；p(Xi) ̸= p(Xj) 且 Yi ∩ Yj = ∅ 对于 i ̸= j
- **测试**: {p(Xt)}t∈T；不提供任务标识

#### Task-Free Continual Learning (TFCL)
- **定义**: 任务具有不相交的数据标签空间。在训练和测试中均不提供任务标识。
- **训练**: \{\{Dt,b\}b∈Bt\}t∈T；p(Xi) ̸= p(Xj) 且 Yi ∩ Yj = ∅ 对于 i ̸= j
- **测试**: {p(Xt)}t∈T；任务标识可选

#### Online Continual Learning (OCL)
- **定义**: 任务具有不相交的数据标签空间。每个任务的训练样本以一次性数据流形式到达。
- **训练**: \{\{Dt,b\}b∈Bt\}t∈T, |b| = 1；p(Xi) ̸= p(Xj) 且 Yi ∩ Yj = ∅ 对于 i ̸= j
- **测试**: {p(Xt)}t∈T；任务标识可选

#### Blurred Boundary Continual Learning (BBCL)
- **定义**: 任务边界模糊，具有不同但重叠的数据标签空间。
- **训练**: {Dt, t}t∈T；p(Xi) ̸= p(Xj), Yi ̸= Yj 且 Yi ∩ Yj ̸= ∅ 对于 i ̸= j
- **测试**: {p(Xt)}t∈T；不提供任务标识

#### Continual Pre-training (CPT)
- **定义**: 预训练数据按顺序到达。目标是改进知识传递到下游任务。
- **训练**: {Dpt t , t}t∈T pt , 随后是下游任务 j
- **测试**: {p(Xt)}t=j；不需要任务标识

#### 其他学习场景
除非特别说明，每个任务通常假定有足够数量的标记训练样本，即监督连续学习。根据每个 Dt 中提供的 Xt 和 Yt，连续学习进一步扩展到零样本学习、少样本学习、半监督学习、开放世界学习（识别未知类别并整合其标签）和无监督/自监督学习场景。此外，还考虑并纳入了其他实际挑战，例如多标签、噪声标签、层次粒度和子群体、任务相似性的混合、长尾分布、域对齐、域迁移、随时推理、新类别发现、多模态等。一些最新的工作集中在这些场景的各种组合上，以更好地模拟现实世界的复杂性。

### 连续学习的性能评估

通常，连续学习的性能可以从三个方面进行评估：已经学习任务的总体性能、旧任务的记忆稳定性和新任务的学习可塑性。以下是常见的评估指标，使用分类作为示例。

#### 总体性能
总体性能通常通过平均准确率 (AA) 和平均增量准确率 (AIA) 来评估。

设 \( a_{k,j} \in [0, 1] \) 表示在增量学习第 \( k \) 个任务后，在第 \( j \) 个任务的测试集上评估的分类准确率 (\( j \leq k \))。计算 \( a_{k,j} \) 的输出空间包括 \( Y_j \) 或 \(\bigcup_{i=1}^{k} Y_i\)，分别对应多头评估 (如 TIL) 或单头评估 (如 CIL)。

第 \( k \) 个任务的两个指标定义如下：
$$
AA_k = \frac{1}{k} \sum_{j=1}^{k} a_{k,j}
$$
$$
AIA_k = \frac{1}{k} \sum_{i=1}^{k} AA_i
$$
其中，AA 代表当前时刻的总体性能，AIA 进一步反映了历史性能。

#### 记忆稳定性
记忆稳定性可以通过遗忘度量 (FM) 和向后传递 (BWT) 来评估。

对于前者，任务的遗忘通过其过去的最大性能与当前性能的差值计算：
$$
f_{j,k} = \max_{i \in \{1,...,k-1\}} (a_{i,j} - a_{k,j}), \forall j < k
$$
第 \( k \) 个任务的 FM 是所有旧任务的平均遗忘：
$$
FM_k = \frac{1}{k-1} \sum_{j=1}^{k-1} f_{j,k}
$$
对于后者，BWT 评估学习第 \( k \) 个任务对所有旧任务的平均影响：
$$
BWT_k = \frac{1}{k-1} \sum_{j=1}^{k-1} (a_{k,j} - a_{j,j})
$$
其中，遗忘通常反映为负的 BWT。

#### 学习可塑性
学习可塑性可以通过不易学习度量 (IM) 和向前传递 (FWT) 来评估。

IM 定义为模型学习新任务的能力不足，通过任务的联合训练性能与持续学习性能之间的差异计算：
$$
IM_k = a^*_k - a_{k,k}
$$
其中，\( a^*_k \) 是随机初始化的参考模型在联合训练 \(\bigcup_{j=1}^{k} D_j\) 时第 \( k \) 个任务的分类准确率。相比之下，FWT 评估所有旧任务对当前第 \( k \) 个任务的平均影响：
$$
FWT_k = \frac{1}{k-1} \sum_{j=2}^{k} (a_{j,j} - \tilde{a}_j)
$$
其中，\( \tilde{a}_j \) 是随机初始化的参考模型在第 \( j \) 个任务的 \( D_j \) 上训练的分类准确率。

#### 其他评估指标
请注意，\( a_{k,j} \) 可以根据任务类型适应其他形式，例如对象检测的平均精度 (AP)、语义分割的交并比 (IoU)、图像生成的 Frechet Inception Distance (FID)、强化学习的标准化奖励等，并应相应调整上述评估指标。此外，还有许多其他有用的指标，例如表示遗忘的线性探针、Hessian 矩阵的最大特征值用于损失景观的平坦性、任何时候推理的准确率曲线下面积、存储和计算的开销用于资源效率等。我们建议读者参考其原始论文。




