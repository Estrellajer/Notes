---
categories:
  - Paper
title: 多模态融合论文阅读
date: 2024-07-15 09:37:40
mathjax: false
tags:
  - 论文阅读
  - 多模态
---
在前向传播中，图像和文本输入首先被嵌入为连续的令牌序列，并送入单模态变换器层进行基础特征提取。两种模态的基础特征随后通过多个基于提示的多模态融合层进行处理，以获取两个CLS令牌的特征，用于最终的分类。在反向传播中，只有多模态融合层参与梯度的计算，这在训练期间大大节省了内存使用量。训练期间，两个变换器中的所有预训练参数都被冻结。
根据之前的讨论，数据在多模态融合模型中的流动和变换可以按以下步骤详细描述：

### 数据流动与变换的步骤：

1. **输入处理**：
   - **图像和文本输入**：首先，图像和文本输入被预处理并嵌入为连续的令牌序列。
   - **单模态变换器层**：这些嵌入序列接着被送入相应的单模态变换器层（例如，一个专门处理文本的变换器和一个处理图像的变换器），在这里它们被转换为基础特征向量。

2. **查询阶段**：
   - **连接查询提示和上下文提示**：特定的查询提示（QP）和查询上下文提示（QCP）与基础特征向量连接，形成一个扩展的特征序列。
   - **单模态处理**：这个扩展的序列通过相应的单模态变换器层进一步处理，以提取和强化模态内的关键信息。
   - **非线性映射**：从查询阶段得到的特征（主要是来自QP的输出）通过非线性映射转换到另一模态的表示空间，为跨模态融合做准备。

3. **融合阶段**：
   - **融合上下文提示**：在融合阶段，融合上下文提示（FCP）与映射后的交叉模态中间体（来自查询阶段的输出）以及另一模态的原始输入连接。
   - **跨模态单模态处理**：这个连接后的序列被送入另一模态的单模态变换器层，进行最终的融合处理。
   - **输出合并**：两个模态的变换器层的输出合并，形成融合后的特征向量，这将被送入更高层或用于最终分类。

### 各变换的实际意义：

- **查询提示（QP）**：主要用于从一个模态中提取对另一模态有用的信息，起到“提问”或“索引关键信息”的作用。
- **查询上下文提示（QCP）**：为查询过程提供上下文支持，帮助改善和指导查询操作的准确性和效率。
- **融合上下文提示（FCP）**：在融合阶段使用，提供必要的上下文以促进两种模态信息的有效融合。
- **非线性映射**：允许将一个模态的输出转换成另一模态能够理解和进一步处理的形式，是实现模态间翻译和理解的关键步骤。
- **跨模态融合**：最终目的是合成一个综合的、跨越语言和视觉界限的表示，用于提高决策或分类的性能。

这种基于提示的多模态融合策略（PMF）利用了深层学习的强大能力，通过精心设计的提示和变换器层来处理和融合不同种类的数据，旨在提高多模态学习任务中的效率和效果。

特定的查询提示（QP）和查询上下文提示（QCP）通常是在模型训练过程中学习得到的。它们作为模型参数的一部分，通过训练数据和反向传播算法进行优化，以达到最佳效果。以下是详细的来源和学习过程：

1. **设计和初始化**：
   - 在模型设计阶段，研究人员或工程师会定义QP（查询提示）和QCP（查询上下文提示）的结构和初始形式。这些提示可以被初始化为随机向量，或者可能使用某种预训练嵌入（如词嵌入）作为起点。

2. **模型训练**：
   - **数据输入**：在训练期间，大量的标注数据（如图像-文本对）被用于教导模型如何处理和理解不同模态的信息。
   - **前向传播**：输入数据通过模型的各层前向传播，其中包括将QP和QCP插入到相应的序列中。
   - **损失计算**：模型输出与真实标签比较，计算损失函数，这通常涉及到分类准确性、信息检索效率等多模态交互指标。
   - **反向传播**：损失函数关于各参数（包括QP和QCP）的梯度被计算并用于更新这些参数。这个过程反复执行，逐渐优化QP和QCP，使其能够更有效地在模态之间查询和传递信息。

3. **优化和调整**：
   - 随着训练的进行，QP和QCP会被优化为能够捕捉关键信息和上下文的表示形式，这对于改进跨模态理解和交互至关重要。
   - 这些提示的优化直接关系到模型在多模态任务中的表现，如图像标注、视频理解或其他需要细致理解和处理多种信息类型的任务。

总之，特定的查询提示（QP）和查询上下文提示（QCP）是通过模型的学习过程自动学到的，它们不是预设的固定参数，而是随着模型训练逐渐调整和优化的动态元素。这使得它们能够在具体的应用场景中表现出高度的适应性和效率。

根据提供的额外内容，下面是对前述回答的完善和补充，重点放在消融研究、模块化、灵活性和使用神经架构搜索（NAS）优化模型结构上：

### 消融研究

- **组件消融**：研究验证了三种提示和非线性映射功能的有效性。结果表明，仅在两个变换器的顶层使用提示并不能实现多模态融合，反而会扰乱特征空间，从而降低性能。尽管映射函数显著提升了性能，但映射函数不能单独工作，必须与查询提示（QP）配合使用来查询融合中间体。
- **提示解耦**：将提示解耦为具有不同学习目标的三个独立模块显示出性能提升。此外，扩展的查询提示（QP）不能替代查询上下文提示（QCP），替换后不仅增加了计算量，还导致性能下降。

- **融合层影响**：不同的融合层 \( L_f \) 对性能和内存效率的影响显示，随着融合开始的层次越晚，训练内存使用量持续减少。然而，当 \( L_f \leq 10 \) 时，融合模型的性能相对一致，因此在深层（\( 10 < l < L \)）添加提示对性能与内存效率之间的折衷更为有利。

- **提示长度**：提示长度的消融研究表明，当提示长度 \( M \leq 16 \) 时，性能随提示长度增加而提升，而过长的提示（\( M = 32 \)）则导致性能下降。训练内存使用量的增加主要由融合层 \( L_f \) 而非提示长度引起。

### 模块化与灵活性

- **模块化设计**：PMF高度模块化，可以轻松替换单模态变换器，以适应更好的模型。这一灵活性允许在使用更大的预训练模型进行实验时，以非常有限的训练内存使用增量来增强PMF。

### 神经架构搜索（NAS）

- **PMF结构搜索**：尽管PMF在未经过深入超参数调优的情况下表现良好，但对于不同的任务和数据分布，最优的融合结构和提示长度设置可能有所不同。通过AutoFormer自动搜索融合结构，减轻了寻找最佳融合结构的工作量，NAS应用的PMF在三个数据集上的性能优于常规PMF，同时增加了训练内存使用量。

### 总结

这些补充内容展示了PMF在多模态学习任务中的高效性、灵活性和可调整性。通过详细的消融研究和模块化设计，PMF能够在保持高性能的同时，有效管理资源消耗。此外，通过利用NAS，PMF能够进一步优化其结构，以适应各种复杂的实际应用场景。