### **🟢 大语言模型的推理能力：无需提示的思维链解码**

在🤖人工智能领域，大语言模型（LLMs），例如GPT-4和PaLM-2，展现出了强大的🧠推理能力。通常，我们通过提示（prompting）技术来激发这些推理能力，但这一过程需要复杂的🛠️手动设计，例如少样本提示和零样本提示。然而，最近的一项研究提出了一个全新的问题：大语言模型能否在没有提示的情况下进行有效推理？这种方法被称为“思维链解码”（CoT-decoding），揭示了LLMs的固有推理能力，而无需依赖人为提示。

#### 现有推理方法的局限性

现有的推理方法主要包括两种：

1. **提示技术**：通过少样本提示或零样本提示来激发模型的🧠推理能力。这种方式虽然有效，但通常依赖于人类的先验知识，难以真实评估模型的内在推理能力。

2. **模型训练**：通过大量的监督数据对模型进行微调，使其学会推理。这种方法代价高昂，且依赖大量的📊标注数据。

#### 思维链解码的创新

这项新研究的核心问题是：**大语言模型是否具备在没有提示的情况下推理的能力？** 研究者通过改变解码过程，而不是使用传统的贪婪解码（即每次选择概率最高的词），来探索模型的推理路径。通过考虑前几个候选词（top-k tokens）的替代路径，他们发现模型能够自然地展现思维链推理能力。

例如，给定问题：“我有🍎3个苹果，我爸爸比我多🍎2个苹果，我们一共有多少个苹果？”

**贪婪解码示例**：
1. 使用贪婪解码时，模型直接选择概率最高的词，得到如下推理：
   - 第一步，模型解码出“5”，最终生成答案为“🍎5个苹果”。
   - 这种情况下，模型并没有展现出逐步推理的能力，只是简单地给出了一个错误的直接答案。

**思维链解码示例**：
1. 使用思维链解码时，我们考虑前几个候选词（例如top-3 tokens）并沿不同路径继续解码。
   - 在某一条路径中，模型首先选择了“我”，然后继续解码：“我有🍎3个苹果，我爸爸比我多🍎2个苹果，所以他有🍎5个苹果，3 + 5 = 8，我们一共有🍎8个苹果”。
   - 在这条路径中，模型展现出了逐步推理的过程，最终得出正确答案“🍎8个苹果”。

通过这种方式，研究者发现，模型内在具备推理能力，只是传统的贪婪解码方法没有充分利用这些能力。

#### 思维链解码的优势

1. **无需提示**：这种方法完全绕过了提示技术，直接激发了模型的内在🧠推理能力，避免了复杂的提示设计。

2. **揭示内在能力**：通过改变解码过程，研究者能够更真实地评估模型的🧠推理能力，而不受人为先验知识的影响。

3. **提高推理准确性**：在数学和常识推理任务中，思维链解码相比贪婪解码表现出显著的改进。例如，在数学推理任务中，选择top-10解码路径中的最优路径，88%的情况下模型能够找到包含思维链的正确解码路径。

#### 思维链解码的局限性

尽管思维链解码在激发模型的推理能力方面展示了巨大的潜力，但它也存在一些局限性：

1. **计算开销高**：与传统的贪婪解码相比，思维链解码需要考虑多个候选路径，这显著增加了计算的复杂性和⏳时间成本。特别是在处理较长的文本或复杂的问题时，计算资源的需求会大幅上升。

2. **路径选择的复杂性**：在实际应用中，选择合适的top-k值是一个挑战。如果选择的k值过大，可能会导致计算成本过高；如果k值过小，则可能错过有效的思维链路径，导致推理失败。

3. **模型的不确定性**：虽然思维链解码能够提高模型的置信度，但并不能保证每次都能找到正确的解码路径。在某些情况下，即使考虑了多个解码路径，模型仍可能得出错误的结论。这种不确定性限制了思维链解码在高精度场景中的应用。

4. **对任务类型的依赖**：思维链解码在一些任务中表现优异，例如数学推理和常识推理，但在其他类型的任务（如语言生成或开放式问答）中，其效果可能不如提示技术或其他方法。这表明思维链解码的适用性并不是通用的，还需要针对不同任务类型进行优化。

#### 关键发现

研究表明，**大语言模型具备内在的🧠推理能力**，这些能力可以通过简单的解码修改来激发，而无需复杂的提示技术。传统的贪婪解码路径往往忽略了这些推理路径，而思维链解码能够有效地找到包含完整推理过程的路径，从而提高模型的推理准确性。

此外，研究还发现，当模型的解码路径中包含思维链时，模型对最终答案的置信度显著提高。这意味着，思维链不仅能帮助模型推理，还能使模型在生成答案时更加确定。

#### 研究意义

这项研究为我们理解和利用大语言模型提供了新的思路。它挑战了“大语言模型无法在没有提示的情况下进行有效推理”的传统观点，揭示了模型潜在的🧠推理能力。这一发现可能推动开发出新的、更高效的🤖AI系统，使得它们能够在更少人为干预的情况下进行复杂推理。

#### 总结

思维链解码为大语言模型的推理能力提供了新的视角。通过简单地改变解码过程，这种方法绕过了提示技术的复杂性，揭示了LLMs的固有🧠推理能力。这不仅有助于我们更好地理解这些模型，也为🤖AI领域的未来研究和应用提供了重要的启示。

如果您对大语言模型的🧠推理能力或思维链解码方法有更多兴趣，欢迎在💬评论区留言讨论！



### **思维链（CoT）能够让Transformer解决固有的串行问题**

Transformer 模型近年来在自然语言处理领域展现出了强大的能力。然而，对于某些需要逐步推理的复杂任务，Transformer 的并行计算特点让它难以表现得很好。那么，如何提升 Transformer 在这些复杂任务上的表现呢？这正是我们今天要讨论的一篇论文所提出的问题。通过引入思维链（Chain of Thought，CoT），这篇论文探索了如何显著提升 Transformer 模型的计算能力，特别是在处理那些需要一步步推理的“串行问题”时。

#### 什么是思维链（Chain of Thought, CoT）？

思维链（CoT）是一种技术，旨在让 Transformer 模型在回答问题之前先生成一系列中间推理步骤，类似于人类解题的思维过程。这种逐步生成的方式，帮助模型更好地理解复杂问题的内在逻辑，从而得出更为精确的答案。

简单来说，如果你让模型回答一个复杂的数学问题，CoT 会让它先写下所有的中间步骤，而不是直接给出最终答案。这种方式不仅可以帮助模型理解问题，还让它能通过“思维过程”更好地得出正确的结论。

#### Transformer 在处理串行问题上的限制

首先，让我们来看看不带有思维链的 Transformer 能处理哪些问题。Transformer 的主要优势是其并行计算能力，因此在处理可并行化的问题时表现非常好。然而，对于那些必须逐步推进的任务（我们称之为**串行问题**），传统 Transformer 在能力上存在严重的不足。

论文中，作者通过理论分析指出，常数深度的 Transformer 在计算能力上受限于 **AC0** 和 **TC0** 复杂度类。简单来说，AC0 和 TC0 都是描述电路计算能力的术语。AC0 允许并行地进行基本的“与/或/非”操作，但不能解决像奇偶性检查（parity）这样的复杂问题。这意味着，没有思维链的 Transformer 很难有效处理一些需要按特定顺序完成的任务。

#### CoT 如何提升 Transformer 的能力？

那么，引入思维链（CoT）后，情况会如何改变呢？

**定理 3.3** 中的一个重要结论是：**带有多项式步骤 CoT 的 Transformer，可以模拟比传统 Transformer 更复杂的电路计算**。这意味着，加入 CoT 后，Transformer 可以通过逐步生成中间推理步骤，逐一处理更复杂的计算逻辑，就像完成一个个“任务关卡”一样。每一步的思维链对应于电路中的一个逻辑门操作，从而帮助模型逐步接近问题的解决方案。

##### 理论推导过程

论文中的理论推导分为几个关键步骤，以证明带有思维链的 Transformer 能够显著提升其表达能力。

1. **有限精度建模：保证结果的现实性**

   - Transformer 的训练和推理通常使用 16 或 32 位浮点数。论文首先引入了 **有限精度的浮点数计算** 模型，解决了以往理论研究中假设的无限精度问题。这种有限精度模型确保了论文中的推导结果更加贴近实际计算机硬件中 Transformer 的工作机制。
   - 使用 $e$ 位的指数和 $s$ 位的尾数来表示浮点数，并在每次算术运算后立即进行舍入，防止无限精度假设。通过这种舍入模型，作者推导出适用于有限精度的 Transformer 计算模型。

2. **Transformer 的表达能力：没有 CoT 的上界**

   - **定理 3.1：AC0 上界**

     - 常数深度、常数精度的 Transformer 只能表达 AC0 复杂度类的函数。AC0 类问题允许常数深度和多项式大小的与/或电路，但不能解决例如奇偶性（parity）这样的任务。

     公式上表示：
     $$
     T[poly(n), 1, 1] \subseteq CoT[\log n, poly(n), 1, 1] \subseteq AC0
     $$

   - **定理 3.2：TC0 上界**

     - 当 Transformer 使用定点数（没有指数位）时，即使进行舍入操作，它的表达能力也可以保持在 TC0 复杂度类内。TC0 电路可以有效并行处理任务，如乘法、模运算等。

     公式上表示：
     $$
     T[poly(n), \log(n), 0] \subseteq CoT[\log n, poly(n), \log(n), 0] \subseteq TC0
     $$

   这些定理证明了，在没有 CoT 的情况下，Transformer 的计算能力受到限制，尤其是在处理复杂的串行任务时。

3. **引入思维链（CoT）：提高表达能力**

   - **定理 3.3：CoT 提高表达能力**

     - 通过引入多项式步骤的 CoT，Transformer 可以通过每一步 CoT 来模拟电路中的一个门操作，这使得模型能够处理复杂的串行任务。具体步骤如下：
       - 每一步 CoT 对应模拟电路中的一个逻辑门，如与、或、非操作。
       - 模型使用注意力机制提取前两个输入门的值，并通过前馈网络计算当前门的值。

     这种模拟过程极大地提升了 Transformer 的表达能力，特别是当嵌入大小为 $\log n$ 时，模型能够正确存储并区分不同位置的门信息。

     公式上表示：
     $$
     SIZE[T(n)] \subseteq CoT[T(n), \log n, 1]
     $$
     这表明，带有多项式 CoT 的 Transformer 可以模拟所有多项式大小的布尔电路，极大拓展了其表达能力。

   - **定理 3.5：置换群 S5 的问题**

     - 在串行任务中，置换群（如 S5）是一个典型的复杂问题。定理 3.5 证明了带有 CoT 的 Transformer 可以解决 S5 的置换问题，而没有 CoT 的 Transformer 无法解决这个问题。

#### 实验验证：CoT 的力量

为了验证 CoT 的有效性，作者通过一系列实验对比了不带 CoT 和带有 CoT 的 Transformer 在不同类型任务上的表现，包括：

- **模加法**：这是一个可以并行化的任务，结果表明，带或不带 CoT 的 Transformer 在处理该任务时表现相似。
- **置换组合（S5）和迭代平方**：这两个任务需要一步步推理才能得到正确答案，属于典型的串行问题。实验结果显示，带有 CoT 的 Transformer 几乎可以达到 100% 的准确率，而没有 CoT 的 Transformer 在这些任务上的表现非常差，准确率仅在 20%-30% 左右。

这些实验结果清楚地表明，**引入思维链能够显著提升 Transformer 在复杂推理任务上的表现，尤其是在深度有限的情况下**。

#### 具体的例子帮助理解

为了更好地理解思维链（CoT）对 Transformer 的提升作用，让我们来看几个具体的例子。

##### 例子 1：模加法任务

考虑一个简单的模加法问题，例如求一组数字的和，然后对结果取模。假设输入是 `[1, 2, 3, 4, 5]`，目标是计算这组数字的和并对 7 取模。对于不带 CoT 的 Transformer，模型需要一次性理解并输出最终结果，这对于深度有限的 Transformer 来说比较困难。而带有 CoT 的 Transformer 可以逐步生成每个数字的加法过程，比如：

- 第一步：`1 + 2 = 3`
- 第二步：`3 + 3 = 6`
- 第三步：`6 + 4 = 10`
- 第四步：`10 + 5 = 15`
- 最后一步：`15 % 7 = 1`

通过逐步计算，带有 CoT 的模型可以显著提高其在模加法任务上的准确性。

##### 例子 2：置换组合任务（S5）

在置换组合任务中，输入是一系列元素的置换，例如 `[2, 3, 1, 5, 4]` 和 `[1, 4, 3, 5, 2]`，目标是求这两个置换的组合。对于这样的任务，模型需要先理解每个置换的含义，然后逐步将它们组合起来，这样的操作必须按特定顺序进行。

带有 CoT 的 Transformer 可以通过以下步骤来解决：

- 第一步：计算第一个置换 `[2, 3, 1, 5, 4]` 的结果。
- 第二步：将结果与第二个置换 `[1, 4, 3, 5, 2]` 进行组合。
- 最后一步：得到最终组合的结果。

通过这种逐步推理的方式，带有 CoT 的模型可以比直接输出最终答案的模型表现更好。

##### 例子 3：迭代平方任务

在迭代平方任务中，输入是一个初始值和一系列平方操作，例如 `2 ^ 2 ^ 2 =`，目标是求出最终结果。带有 CoT 的 Transformer 可以逐步计算：

- 第一步：`2 ^ 2 = 4`
- 第二步：`4 ^ 2 = 16`

这样逐步计算的方式帮助模型更好地理解每一步的推理过程，从而得出正确的最终答案。

#### 为什么思维链这么有效？

思维链的有效性可以从几个方面理解：
1. **逐步推理**：通过分解任务，模型可以逐步理解并解决复杂问题，而不是试图一次性给出最终答案。
2. **减少错误积累**：在没有思维链的情况下，模型容易因为中间推理错误而导致最终答案错误。而通过 CoT，模型可以一步步检查自己的推理过程，减少错误的积累。
3. **增强推理的表达能力**：CoT 本质上是将模型的计算能力从简单的“并行计算”提升到复杂的“串行推理”，从而能够处理更多样的任务类型。

#### 总结与未来展望

这篇论文为我们展示了如何通过引入思维链（Chain of Thought）来大幅度提升 Transformer 的推理能力，特别是在处理那些需要逐步推理的复杂任务时。通过理论分析和实验证明，带有 CoT 的 Transformer 能够模拟更复杂的电路计算，并在多个串行问题上表现出了远超没有 CoT 的模型的能力。

这种研究为未来的 Transformer 设计和改进提供了新的思路。或许未来的人工智能系统可以更像人类一样，逐步思考、分解问题，从而解决更复杂的任务。这不仅能提升模型的准确性，还可能让模型在处理复杂任务时更加透明和可解释。





好的人工智能->zero shot的推理能力



数据，领域知识，

微调